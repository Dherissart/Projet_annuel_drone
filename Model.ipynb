{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from camera import CameraPoses\n",
    "\n",
    "def create_point_cloud_file(points, colors, filename):\n",
    "\tcolors = colors.reshape(-1,3)\n",
    "\tpoints = np.hstack([points.reshape(-1,3),colors])\n",
    "\n",
    "\tply_header = '''ply\n",
    "\t\tformat ascii 1.0\n",
    "\t\telement vertex %(vert_num)d\n",
    "\t\tproperty float x\n",
    "\t\tproperty float y\n",
    "\t\tproperty float z\n",
    "\t\tproperty uchar red\n",
    "\t\tproperty uchar green\n",
    "\t\tproperty uchar blue\n",
    "\t\tend_header\n",
    "\t\t'''\n",
    "\twith open(filename, 'w') as f:\n",
    "\t\tf.write(ply_header %dict(vert_num=len(points)))\n",
    "\t\tnp.savetxt(f,points,'%f %f %f %d %d %d')\n",
    "\n",
    "# Chargement du model\n",
    "model_type = \"DPT_Hybrid\"\n",
    "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type)\n",
    "\n",
    "# Défini le périphérie pour l'excécution du model\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "midas.to(device)\n",
    "\n",
    "# Chargement du preprocessing pour utiliser le model MiDaS\n",
    "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
    "transform = midas_transforms.dpt_transform\n",
    "\n",
    "# Initialisation des variables (paramètrable)\n",
    "intrinsic = np.array([\n",
    "    [527.70703125,   0.        , 335.40994459],\n",
    "    [  0.        , 525.81518555, 253.63149488],\n",
    "    [  0.        ,   0.        ,   1.        ]]) # parametre d'une caméra d'un pc\n",
    "\n",
    "\n",
    "def reconstruction(path_to_video, path_to_save_ply, intrinsic=intrinsic, skip_frames=50, log=False, fx=480):\n",
    "\n",
    "    cap = cv2.VideoCapture(path_to_video) # Insérer l'url de la video à traiter (ex: './deer_vr_slow.mp4')\n",
    "    ret, img = cap.read()\n",
    "    start_pose = np.array([\n",
    "        [   1.,    0.,    0.,    -img.shape[0]/2],\n",
    "        [   0.,    1.,    0.,    -img.shape[1]/2],\n",
    "        [   0.,    0.,    0.,                 fx]])\n",
    "    cur_pose = start_pose\n",
    "\n",
    "    hom_array = np.array([[0,0,1.0/90.0,0]])\n",
    "    extrinsic = np.concatenate((cur_pose, hom_array), axis=0)\n",
    "\n",
    "    first_frame = True\n",
    "    prev_img = None\n",
    "    cam = CameraPoses(intrinsic)\n",
    "\n",
    "    frame = 0\n",
    "    while cap.isOpened():\n",
    "        ret, img = cap.read()\n",
    "        if not ret:\n",
    "            # La lecture est terminée, sortir de la boucle\n",
    "            break\n",
    "\n",
    "        frame += 1\n",
    "        if log: print(frame) # Compter le nombre de frame actuel\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        if not first_frame:\n",
    "            q1, q2 = cam.get_matches(prev_img, img) # Détection des points communs avec l'image précédent\n",
    "            if q1 is not None:\n",
    "                if len(q1) > 20 and len(q2) > 20:\n",
    "                    transf = cam.get_pose(q1, q2)   # Obtention de l'écart de position\n",
    "                    cur_pose = cur_pose @ transf    # Mise à jour de la position\n",
    "                    prev_img = img\n",
    "            hom_array = np.array([[0,0,1/90,0]])\n",
    "            extrinsic = np.concatenate((cur_pose,hom_array), axis=0)\n",
    "            extrinsic = np.round(extrinsic, 8)\n",
    "        else:\n",
    "            prev_img = img\n",
    "\n",
    "        # Skip pour ne pas trop chargarger de point cloud répété\n",
    "        if frame % skip_frames != 1:\n",
    "            continue\n",
    "\n",
    "        img_trans = transform(img).to(device)\n",
    "\n",
    "        # Prediction\n",
    "        with torch.no_grad():\n",
    "            prediction = midas(img_trans)\n",
    "            prediction = torch.nn.functional.interpolate(\n",
    "                prediction.unsqueeze(1),\n",
    "                size=img.shape[:2],\n",
    "                mode=\"bicubic\",\n",
    "                align_corners=False,\n",
    "            ).squeeze()\n",
    "\n",
    "        depth_image = prediction.cpu().numpy()\n",
    "\n",
    "        depth_image = cv2.normalize(depth_image, None, 0, 1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "        # Convertion en points cloud\n",
    "        points_3D = cv2.reprojectImageTo3D(depth_image*200, extrinsic, handleMissingValues=False)\n",
    "        points_3D = cv2.perspectiveTransform(points_3D.reshape(-1, 1, 3), extrinsic)\n",
    "        points_3D = points_3D.reshape(img.shape)\n",
    "\n",
    "        # Filtre\n",
    "        filtre = depth_image > 0.1\n",
    "\n",
    "        #Mask colors and points.\n",
    "        points_cloud = points_3D[filtre]\n",
    "        image_colors = img[filtre]\n",
    "\n",
    "        if first_frame:\n",
    "            points_cloud_global = points_cloud\n",
    "            image_colors_global = image_colors\n",
    "        else:\n",
    "            points_cloud_global = np.concatenate((points_cloud_global, points_cloud), axis=0)\n",
    "            image_colors_global = np.concatenate((image_colors_global, image_colors), axis=0)\n",
    "\n",
    "        create_point_cloud_file(points_cloud_global, image_colors_global, path_to_save_ply)\n",
    "\n",
    "        if log:\n",
    "            fig, (ax1, ax2, ax3) = plt.subplots(1,3)\n",
    "            ax1.imshow(img)\n",
    "            ax2.imshow((depth_image*255).astype(np.uint8))\n",
    "            depth_image[depth_image < 0.1] = 0\n",
    "            ax3.imshow((depth_image*255).astype(np.uint8))\n",
    "            plt.show()\n",
    "            first_frame = False\n",
    "            print(extrinsic)\n",
    "\n",
    "            if cv2.waitKey(5) & 0xFF == 27:\n",
    "                break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
