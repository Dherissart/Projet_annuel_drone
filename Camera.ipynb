{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "\n",
    "import os\n",
    "\n",
    "class CameraPoses():\n",
    "\n",
    "    def __init__(self, intrinsic):\n",
    "\n",
    "        self.K = intrinsic\n",
    "        self.extrinsic = np.array(((1,0,0,0),(0,1,0,0),(0,0,1,0)))\n",
    "        self.P = self.K @ self.extrinsic\n",
    "        self.orb = cv2.ORB_create(3000)\n",
    "        FLANN_INDEX_LSH = 6\n",
    "        index_params = dict(algorithm=FLANN_INDEX_LSH, table_number=6, key_size=12, multi_probe_level=1)\n",
    "        search_params = dict(checks=50)\n",
    "        self.flann = cv2.FlannBasedMatcher(indexParams=index_params, searchParams=search_params)\n",
    "\n",
    "        self.world_points = []\n",
    "\n",
    "        self.current_pose = None\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_images(filepath, skip_frames):\n",
    "\n",
    "        image_paths = [os.path.join(filepath, file) for file in sorted(os.listdir(filepath))]\n",
    "        images = []\n",
    "\n",
    "        for path in tqdm(image_paths[::skip_frames]):\n",
    "            img = cv2.imread(path)\n",
    "            if img is not None:\n",
    "                #images.append(cv2.resize(img, (640,480)))\n",
    "                images.append(img)\n",
    "\n",
    "        return images\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _form_transf(R, t):\n",
    "\n",
    "        T = np.eye(4, dtype=np.float64)\n",
    "        T[:3, :3] = R\n",
    "        T[:3, 3] = t\n",
    "\n",
    "        return T\n",
    "\n",
    "    def get_world_points(self):\n",
    "        return np.array(self.world_points)\n",
    "\n",
    "    def get_matches(self, img1, img2):\n",
    "\n",
    "        # Find the keypoints and descriptors with ORB\n",
    "        kp1, des1 = self.orb.detectAndCompute(img1, None)\n",
    "        kp2, des2 = self.orb.detectAndCompute(img2, None)\n",
    "        # Find matches\n",
    "        if len(kp1) > 6 and len(kp2) > 6:\n",
    "            matches = self.flann.knnMatch(des1, des2, k=2)\n",
    "\n",
    "            # Find the matches there do not have a to high distance\n",
    "            good_matches = []\n",
    "            try:\n",
    "                for m, n in matches:\n",
    "                    if m.distance < 0.5 * n.distance:\n",
    "                        good_matches.append(m)\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "            # Draw matches\n",
    "            #img_matches = np.empty((max(img1.shape[0], img2.shape[0]), img1.shape[1] + img2.shape[1], 3), dtype=np.uint8)\n",
    "            #cv2.drawMatches(img1, kp1, img2, kp2, good_matches, img_matches, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "            #plt.imshow(img_matches)\n",
    "            #plt.title(\"Good Matches\")\n",
    "            #plt.show()\n",
    "            #cv2.waitKey(50)\n",
    "\n",
    "            # Get the image points form the good matches\n",
    "            #q1 = [kp1[m.queryIdx] for m in good_matches]\n",
    "            #q2 = [kp2[m.trainIdx] for m in good_matches]\n",
    "            q1 = np.float32([kp1[m.queryIdx].pt for m in good_matches])\n",
    "            q2 = np.float32([kp2[m.trainIdx].pt for m in good_matches])\n",
    "\n",
    "            return q1, q2\n",
    "        else:\n",
    "            return None, None\n",
    "\n",
    "    def get_pose(self, q1, q2):\n",
    "\n",
    "        # Essential matrix\n",
    "        E, mask = cv2.findEssentialMat(q1, q2, self.K)\n",
    "\n",
    "        # Decompose the Essential matrix into R and t\n",
    "        R, t = self.decomp_essential_mat_old(E, q1, q2)\n",
    "\n",
    "        # Get transformation matrix\n",
    "        transformation_matrix = self._form_transf(R, np.squeeze(t))\n",
    "\n",
    "        return transformation_matrix\n",
    "\n",
    "\n",
    "    def decomp_essential_mat(self, E, q1, q2):\n",
    "\n",
    "        R1, R2, t = cv2.decomposeEssentialMat(E)\n",
    "        T1 = self._form_transf(R1,np.ndarray.flatten(t))\n",
    "        T2 = self._form_transf(R2,np.ndarray.flatten(t))\n",
    "        T3 = self._form_transf(R1,np.ndarray.flatten(-t))\n",
    "        T4 = self._form_transf(R2,np.ndarray.flatten(-t))\n",
    "        transformations = [T1, T2, T3, T4]\n",
    "\n",
    "        # Homogenize K\n",
    "        K = np.concatenate((self.K, np.zeros((3,1)) ), axis = 1)\n",
    "\n",
    "        # List of projections\n",
    "        projections = [K @ T1, K @ T2, K @ T3, K @ T4]\n",
    "\n",
    "        np.set_printoptions(suppress=True)\n",
    "\n",
    "        # print (\"\\nTransform 1\\n\" +  str(T1))\n",
    "        # print (\"\\nTransform 2\\n\" +  str(T2))\n",
    "        # print (\"\\nTransform 3\\n\" +  str(T3))\n",
    "        # print (\"\\nTransform 4\\n\" +  str(T4))\n",
    "\n",
    "        positives = []\n",
    "        for P, T in zip(projections, transformations):\n",
    "            hom_Q1 = cv2.triangulatePoints(P, P, q1.T, q2.T)\n",
    "            hom_Q2 = T @ hom_Q1\n",
    "            # Un-homogenize\n",
    "            Q1 = hom_Q1[:3, :] / hom_Q1[3, :]\n",
    "            Q2 = hom_Q2[:3, :] / hom_Q2[3, :]\n",
    "\n",
    "            total_sum = sum(Q2[2, :] > 0) + sum(Q1[2, :] > 0)\n",
    "            relative_scale = np.mean(np.linalg.norm(Q1.T[:-1] - Q1.T[1:], axis=-1)/\n",
    "                                     np.linalg.norm(Q2.T[:-1] - Q2.T[1:], axis=-1))\n",
    "            positives.append(total_sum + relative_scale)\n",
    "\n",
    "\n",
    "        # Decompose the Essential matrix using built in OpenCV function\n",
    "        # Form the 4 possible transformation matrix T from R1, R2, and t\n",
    "        # Create projection matrix using each T, and triangulate points hom_Q1\n",
    "        # Transform hom_Q1 to second camera using T to create hom_Q2\n",
    "        # Count how many points in hom_Q1 and hom_Q2 with positive z value\n",
    "        # Return R and t pair which resulted in the most points with positive z\n",
    "\n",
    "        max = np.argmax(positives)\n",
    "        if (max == 2):\n",
    "            # print(-t)\n",
    "            return R1, np.ndarray.flatten(-t)\n",
    "        elif (max == 3):\n",
    "            # print(-t)\n",
    "            return R2, np.ndarray.flatten(-t)\n",
    "        elif (max == 0):\n",
    "            # print(t)\n",
    "            return R1, np.ndarray.flatten(t)\n",
    "        elif (max == 1):\n",
    "            # print(t)\n",
    "            return R2, np.ndarray.flatten(t)\n",
    "\n",
    "\n",
    "    def decomp_essential_mat_old(self, E, q1, q2):\n",
    "        def sum_z_cal_relative_scale(R, t):\n",
    "            # Get the transformation matrix\n",
    "            T = self._form_transf(R, t)\n",
    "            # Make the projection matrix\n",
    "            P = np.matmul(np.concatenate((self.K, np.zeros((3, 1))), axis=1), T)\n",
    "\n",
    "            # Triangulate the 3D points\n",
    "            hom_Q1 = cv2.triangulatePoints(self.P, P, q1.T, q2.T)\n",
    "            # Also seen from cam 2\n",
    "            hom_Q2 = np.matmul(T, hom_Q1)\n",
    "\n",
    "            # Un-homogenize\n",
    "            Q1 = hom_Q1[:3, :] / hom_Q1[3, :]\n",
    "            Q2 = hom_Q2[:3, :] / hom_Q2[3, :]\n",
    "\n",
    "            #self.world_points.append(Q1)\n",
    "\n",
    "            # Find the number of points there has positive z coordinate in both cameras\n",
    "            sum_of_pos_z_Q1 = sum(Q1[2, :] > 0)\n",
    "            sum_of_pos_z_Q2 = sum(Q2[2, :] > 0)\n",
    "\n",
    "            # Form point pairs and calculate the relative scale\n",
    "            relative_scale = np.mean(np.linalg.norm(Q1.T[:-1] - Q1.T[1:], axis=-1)/\n",
    "                                     np.linalg.norm(Q2.T[:-1] - Q2.T[1:], axis=-1))\n",
    "            return sum_of_pos_z_Q1 + sum_of_pos_z_Q2, relative_scale\n",
    "\n",
    "        # Decompose the essential matrix\n",
    "        R1, R2, t = cv2.decomposeEssentialMat(E)\n",
    "        t = np.squeeze(t)\n",
    "\n",
    "        # Make a list of the different possible pairs\n",
    "        pairs = [[R1, t], [R1, -t], [R2, t], [R2, -t]]\n",
    "\n",
    "        # Check which solution there is the right one\n",
    "        z_sums = []\n",
    "        relative_scales = []\n",
    "        for R, t in pairs:\n",
    "            z_sum, scale = sum_z_cal_relative_scale(R, t)\n",
    "            z_sums.append(z_sum)\n",
    "            relative_scales.append(scale)\n",
    "\n",
    "        # Select the pair there has the most points with positive z coordinate\n",
    "        right_pair_idx = np.argmax(z_sums)\n",
    "        right_pair = pairs[right_pair_idx]\n",
    "        relative_scale = relative_scales[right_pair_idx]\n",
    "        R1, t = right_pair\n",
    "        t = t * relative_scale\n",
    "\n",
    "        T = self._form_transf(R1, t)\n",
    "        # Make the projection matrix\n",
    "        P = np.matmul(np.concatenate((self.K, np.zeros((3, 1))), axis=1), T)\n",
    "\n",
    "        # Triangulate the 3D points\n",
    "        hom_Q1 = cv2.triangulatePoints(P, P, q1.T, q2.T)\n",
    "        # Also seen from cam 2\n",
    "        hom_Q2 = np.matmul(T, hom_Q1)\n",
    "\n",
    "        # Un-homogenize\n",
    "        Q1 = hom_Q1[:3, :] / hom_Q1[3, :]\n",
    "        Q2 = hom_Q2[:3, :] / hom_Q2[3, :]\n",
    "\n",
    "        self.world_points.append(Q1)\n",
    "\n",
    "        return [R1, t]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
